import yaml
import openai
import os

# Import API info
with open('/etc/secret-volume/env', 'r') as f:
    env = yaml.safe_load(f)

# Configure OpenAI API for use with fastchat
openai.api_key = env["fastchat"]["api_key"]
openai.api_base = env["fastchat"]["base_url"]

# Get Kubernetes JOB_COMPLETION_INDEX
index = int(os.environ["JOB_COMPLETION_INDEX"])

# Model can be replaced with the model id from the previous call
model = "vicuna-33b-v1.3"

# Generated by ChatGPT3.5-Turbo
chat_prompts = [
    "Define GPT-3.5 architecture briefly.",
    "Discuss applications of language models.",
    "Explain AI biases in language models.",
    "Explore ethical concerns in AI language models.",
    "Compare GPT-3.5 to earlier language models.",
    "Describe challenges in training large models.",
    "How do language models generate text?",
    "Discuss fine-tuning in language models.",
    "Examine the impact of language models on jobs.",
    "Explore the role of language models in education.",
    "Discuss the limitations of large language models.",
    "Explain the concept of transfer learning.",
    "Explore the scalability of language models.",
    "Discuss the future of language model research.",
    "Examine potential risks of powerful AI models.",
    "Compare GPT-3.5 to BERT and other models.",
    "How do language models handle code generation?",
    "Discuss the role of language models in chatbots.",
    "Examine challenges in mitigating model biases.",
    "Explore the role of language models in creativity.",
    "Discuss the societal impact of AI language models.",
    "Examine the environmental impact of training models.",
    "How can language models aid in content creation?",
    "Explore the concept of explainability in AI models.",
    "Discuss the need for diverse training data.",
    "Examine the trade-off between model size and efficiency.",
    "How do language models impact natural language understanding?",
    "Discuss the interpretability of language models.",
    "Explore potential breakthroughs in language model research.",
    "Examine the impact of language models on communication.",
    "Discuss the role of language models in healthcare.",
    "Examine challenges in controlling AI-generated content.",
    "Explore the role of language models in multilingual applications.",
    "Discuss the implications of open-sourcing language models.",
    "Examine the use of language models in content summarization.",
    "How can language models enhance search engines?",
    "Discuss the role of language models in sentiment analysis.",
    "Examine challenges in building inclusive language models.",
    "Explore the role of language models in virtual assistants.",
    "Discuss the role of language models in combating misinformation.",
    "Examine the impact of language models on creative writing.",
    "How do language models contribute to natural language processing?",
    "Discuss the scalability challenges in deploying large models.",
    "Examine the role of language models in personalized content.",
    "Explore the trade-offs in pre-training and fine-tuning.",
    "Discuss the impact of language models on content generation.",
    "Examine the role of language models in automated translation.",
    "How can language models be used for code understanding?",
    "Discuss the role of language models in autonomous systems."
]

# Create a chat completion
completion = openai.ChatCompletion.create(
  model=model,
  messages=[
      {"role": "system", "content": "You are an expert on large language models. Answer the question succintly."},
      {"role": "user", "content": chat_prompts[index]}
  ]
)

# print the completion
print(completion.choices[0].message.content)